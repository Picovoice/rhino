<!doctype html>
<html lang="en">
  <head>
    <script src="node_modules/@picovoice/rhino-web/dist/iife/index.js"></script>
    <script src="node_modules/@picovoice/web-voice-processor/dist/iife/index.js"></script>
    <script src="contexts/rhinoContext.js"></script>
    <script src="models/rhinoModel.js"></script>
    <script type="application/javascript" src="scripts/rhino.js"></script>
  </head>
  <body>
    <h1>Rhino Web Demo</h1>
    <p>This demo uses Rhino for Web and the WebVoiceProcessor to:</p>
    <ol>
      <li>
        Create an instance of Rhino that understands commands in the within a
        given sample context;
      </li>
      <li>
        Acquire microphone (& ask permission) data stream and convert to voice
        processing format (16kHz 16-bit linear PCM). The downsampled audio is
        forwarded to the Rhino engine. The audio <i>does not</i> leave the
        browser: all processing is occurring via the Rhino WebAssembly code.
      </li>
      <li>
        Await inference events from the Rhino engine and output them to the
        page. When the inference is concluded, the push-to-talk button is
        enabled again.
      </li>
    </ol>
    After entering the AccessKey, click the "Start Rhino" button.
    <hr />
    <label for="accessKey"
      >AccessKey obtained from
      <a href="https://picovoice.ai/console/">Picovoice Console</a>:</label
    >
    <input type="text" id="accessKey" name="accessKey" />
    <input
      type="button"
      id="submit"
      value="Start Rhino"
      onclick="startRhino(document.getElementById('accessKey').value)"
    />
    <button id="push-to-talk" disabled>Push to Talk</button>
    <hr />
    <div id="messages" style="white-space: pre"></div>
    <br />
    <hr />
    <h2>Context info:</h2>
    <pre id="rhn-context-yaml"></pre>
  </body>
</html>
